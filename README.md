# ğŸ›¡ï¸ AI Agent Security Research

> *Documenting how AI coding agents get exploited -- so we can build better defenses.*

[![Educational](https://img.shields.io/badge/Purpose-Educational%20%26%20Defensive-blue)]()
[![AI Agents](https://img.shields.io/badge/Scope-AI%20Coding%20Agents-purple)]()
[![No Live Exploits](https://img.shields.io/badge/Exploits-None%20Executable-green)]()

---

## ğŸ” What This Is

A growing collection of research, annotated attack examples, and defense strategies targeting the security of **AI coding agents** -- Claude Code, Cursor, Copilot, Windsurf, and the broader ecosystem of LLM-powered development tools.

Every attack has a defense. Every payload is annotated, defanged, and educational.

---

## ğŸ“ Research Notes

| | Topic | What You'll Learn |
|---|-------|-------------------|
| ğŸ¯ | [Prompt Injection Overview](notes/01_Prompt_Injection_Overview.md) | The foundational attack -- how untrusted input hijacks agent behavior |
| ğŸ’‰ | [Skill Injection Analysis](notes/02_Skill_Injection_Analysis.md) | Real-world trojanized skill teardown (ZackKorman `security-review` case) |
| ğŸ§± | [Defense Patterns](notes/03_Defense_Patterns.md) | Sanitization, sandboxing, and mitigation strategies with working code |
| ğŸ”¬ | [Research Findings](notes/04_Research_Findings.md) | Cutting-edge attacks (2024-2026): MCP poisoning, memory corruption, vibe coding risks |
| âš™ï¸ | [Claude Code Skill Architecture](notes/05_Claude_Code_Skill_Architecture.md) | How Claude Code's extensibility (skills, hooks, MCP) creates attack surface |
| ğŸ‘» | [LLM Hallucination Prevention](notes/06_LLM_Hallucination_Prevention.md) | Why models invent things, how to detect it, and how to stop it |
| ğŸŒ | [AI Coding Language Performance](notes/07_AI_Coding_Language_Performance.md) | Multilingual benchmarks, token efficiency, and language-steering attacks |
| ğŸ”“ | [LLM Jailbreaking Deep Dive](notes/08_LLM_Jailbreaking_Deep_Dive.md) | Full taxonomy: DAN to GCG to Crescendo, defenses, benchmarks, agent implications |
| ğŸ” | [Skill Scanning & Detection Landscape](notes/09_Skill_Scanning_And_Detection_Landscape.md) | Cisco Skill Scanner, VirusTotal, ToxicSkills audit, gap analysis, what to build next |

---

## ğŸ§ª Attack / Defense Examples

Hands-on annotated scenarios -- each one shows the attack **and** the fix.

| | Technique | TL;DR |
|---|-----------|-------|
| ğŸ•µï¸ | [Hidden Comment Injection](examples/01_Hidden_Comment_Injection/) | HTML comments are invisible in markdown previews but the LLM reads every word |
| ğŸŒŠ | [Indirect Prompt Injection](examples/02_Indirect_Prompt_Injection/) | Poison the web page, API response, or file the agent fetches -- it obeys |
| ğŸ“¤ | [Data Exfiltration Via Agent](examples/03_Data_Exfiltration_Via_Agent/) | The agent becomes an unwitting mule for your secrets, keys, and credentials |
| ğŸ“¦ | [Hallucinated Package Injection](examples/04_Hallucinated_Package_Skill_Injection/) | LLM invents a package name, attacker registers it -- instant supply chain attack |

---

## ğŸ—‚ï¸ Attack Taxonomy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  AI Agent Attacks                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ¯ Injection â”‚ ğŸ”— Supply    â”‚ ğŸ“¤ Exfiltration       â”‚
â”‚              â”‚    Chain     â”‚                       â”‚
â”‚ Direct       â”‚ Trojan       â”‚ Secrets & keys        â”‚
â”‚ Indirect     â”‚  skills      â”‚ Source code           â”‚
â”‚ Hidden       â”‚ Hallucinated â”‚ Environment           â”‚
â”‚  comments    â”‚  packages    â”‚  variables            â”‚
â”‚ MCP tool     â”‚ Poisoned     â”‚ Credentials           â”‚
â”‚  poisoning   â”‚  docs        â”‚                       â”‚
â”‚ Language-    â”‚              â”‚                       â”‚
â”‚  steering    â”‚              â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Project Structure

```
AI-Agent-Security/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“ notes/            # Research writeups and analysis
â”œâ”€â”€ ğŸ§ª examples/         # Annotated attack/defense pairs
â””â”€â”€ ğŸ”§ tools/            # Detection & sanitization scripts (planned)
```

---

## âš ï¸ Disclaimer

This research is for **educational and defensive purposes only**. All examples use defanged URLs (`hxxps://`, `[.]`), annotated payloads marked `[MALICIOUS]`, and non-executable demonstrations. Every attack technique includes corresponding defenses.

---

## ğŸ“œ License

MIT
